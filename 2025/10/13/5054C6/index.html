<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"tianyaoblogs.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="统计机器学习Lecture-6 Lecturer: Prof.XIA DONG 1. Linear Model Selection and Regularization 线性模型选择与正则化 Summary of Core Concepts Chapter 6: Linear Model Selection and Regularization, focusing specifica">
<meta property="og:type" content="article">
<meta property="og:title" content="MSDM 5054 - Statistical Machine Learning-L6">
<meta property="og:url" content="https://tianyaoblogs.github.io/2025/10/13/5054C6/index.html">
<meta property="og:site_name" content="TianyaoBlogs">
<meta property="og:description" content="统计机器学习Lecture-6 Lecturer: Prof.XIA DONG 1. Linear Model Selection and Regularization 线性模型选择与正则化 Summary of Core Concepts Chapter 6: Linear Model Selection and Regularization, focusing specifica">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-10-13T13:00:00.000Z">
<meta property="article:modified_time" content="2025-10-19T19:21:23.759Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="Machine Learning">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://tianyaoblogs.github.io/2025/10/13/5054C6/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>MSDM 5054 - Statistical Machine Learning-L6 | TianyaoBlogs</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">TianyaoBlogs</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://tianyaoblogs.github.io/2025/10/13/5054C6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="TianyaoBlogs">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          MSDM 5054 - Statistical Machine Learning-L6
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-10-13 21:00:00" itemprop="dateCreated datePublished" datetime="2025-10-13T21:00:00+08:00">2025-10-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-10-20 03:21:23" itemprop="dateModified" datetime="2025-10-20T03:21:23+08:00">2025-10-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>统计机器学习Lecture-6</p>
<p><a target="_blank" rel="noopener" href="https://www.math.hkust.edu.hk/~madxia/">Lecturer: Prof.XIA
DONG</a></p>
<h1
id="linear-model-selection-and-regularization-线性模型选择与正则化">1.
Linear Model Selection and Regularization 线性模型选择与正则化</h1>
<h2 id="summary-of-core-concepts">Summary of Core Concepts</h2>
<p><strong>Chapter 6: Linear Model Selection and
Regularization</strong>, focusing specifically on <strong>Section 6.1:
Subset Selection</strong>.
<strong>第六章：线性模型选择与正则化</strong>，<strong>6.1节：子集选择</strong></p>
<ul>
<li><p><strong>The Problem:</strong> You have a dataset with many
potential predictor variables (features). If you include all of them
(like <strong>Model 1</strong> with <span
class="math inline">\(p\)</span> predictors in slide
<code>...221320.png</code>), you risk including “noise” variables. These
irrelevant features can decrease model accuracy (overfitting) and make
the model difficult to interpret.
数据集包含许多潜在的预测变量（特征）。如果包含所有这些变量（例如幻灯片“…221320.png”中带有<span
class="math inline">\(p\)</span>个预测变量的<strong>模型1</strong>），则可能会包含“噪声”变量。这些不相关的特征会降低模型的准确率（过拟合），并使模型难以解释。</p></li>
<li><p><strong>The Goal:</strong> Identify a smaller subset of variables
that are truly related to the response. This creates a simpler, more
interpretable, and often more accurate model (like <strong>Model
2</strong> with <span class="math inline">\(q\)</span> predictors).
找出一个与响应真正相关的较小变量子集。这将创建一个更简单、更易于解释且通常更准确的模型（例如带有<span
class="math inline">\(q\)</span>个预测变量的<strong>模型2</strong>）。</p></li>
<li><p><strong>The Main Method Discussed: Best Subset
Selection</strong></p></li>
<li><p><strong>主要讨论的方法：最佳子集选择</strong> This is an
<em>exhaustive search</em> algorithm. It checks <em>every possible
combination</em> of predictors to find the “best” model. With <span
class="math inline">\(p\)</span> variables, this means checking <span
class="math inline">\(2^p\)</span> total models.
这是一种<em>穷举搜索</em>算法。它检查<em>所有可能的预测变量组合</em>，以找到“最佳”模型。对于
<span class="math inline">\(p\)</span> 个变量，这意味着需要检查总共
<span class="math inline">\(2^p\)</span> 个模型。</p>
<p>The algorithm (from slide <code>...221333.png</code>) works in three
steps:</p>
<ol type="1">
<li><p><strong>Step 1:</strong> Fit the “null model” <span
class="math inline">\(M_0\)</span>, which has no predictors (it just
predicts the average of the response). 拟合“空模型”<span
class="math inline">\(M_0\)</span>，它没有预测变量（它只预测响应的平均值）。</p></li>
<li><p><strong>Step 2:</strong> For each <span
class="math inline">\(k\)</span> (from 1 to <span
class="math inline">\(p\)</span>):</p>
<ul>
<li><p>Fit all <span class="math inline">\(\binom{p}{k}\)</span> models
that contain exactly <span class="math inline">\(k\)</span> predictors.
(e.g., fit all models with 1 predictor, then all models with 2
predictors, etc.).</p></li>
<li><p>拟合所有包含 <span class="math inline">\(k\)</span> 个预测变量的
<span class="math inline">\(\binom{p}{k}\)</span>
个模型。（例如，先拟合所有包含 1 个预测变量的模型，然后拟合所有包含 2
个预测变量的模型，等等）。</p></li>
<li><p>From this group, select the single best model <em>for that size
<span class="math inline">\(k\)</span></em>. This “best” model is the
one with the highest <strong><span
class="math inline">\(R^2\)</span></strong> (or lowest
<strong>RSS</strong> - Residual Sum of Squares) on the <em>training
data</em>. Call this model <span
class="math inline">\(M_k\)</span>.</p></li>
<li><p>从这组中，选择 <em>对于该规模 <span
class="math inline">\(k\)</span></em> 的最佳模型。这个“最佳”模型是在
<em>训练数据</em> 上具有最高 <strong><span
class="math inline">\(R^2\)</span></strong>（或最低 <strong>RSS</strong>
- 残差平方和）的模型。将此模型称为 <span
class="math inline">\(M_k\)</span>。</p></li>
</ul></li>
<li><p><strong>Step 3:</strong> You now have <span
class="math inline">\(p+1\)</span> models: <span
class="math inline">\(M_0, M_1, \dots, M_p\)</span>. You must select the
single best one from this list. To do this, you <strong>cannot</strong>
use training <span class="math inline">\(R^2\)</span> (as it will always
pick the biggest model <span class="math inline">\(M_p\)</span>).
Instead, you must use a metric that estimates <em>test error</em>, such
as: <strong>现在你有 <span class="math inline">\(p+1\)</span>
个模型：<span class="math inline">\(M_0, M_1, \dots,
M_p\)</span>。你必须从列表中选择一个最佳模型。为此，你</strong>不能**使用训练
<span class="math inline">\(R^2\)</span>（因为它总是会选择最大的模型
<span
class="math inline">\(M_p\)</span>）。相反，你必须使用一个能够估计<em>测试误差</em>的指标，例如：</p>
<ul>
<li><strong>Cross-Validation (CV) 交叉验证 (CV)</strong> (This is what
the Python code uses)</li>
<li><strong>AIC</strong> (Akaike Information Criterion
赤池信息准则)</li>
<li><strong>BIC</strong> (Bayesian Information Criterion
贝叶斯信息准则)</li>
<li><strong>Adjusted <span class="math inline">\(R^2\)</span> 调整后的
<span class="math inline">\(R^2\)</span></strong></li>
</ul></li>
</ol></li>
<li><p><strong>Key Takeaway:</strong> The slides show this “subset
selection” concept can be applied <em>beyond</em> linear models. The
Python code demonstrates this by applying best subset selection to a
<strong>K-Nearest Neighbors (KNN) Regressor</strong>, a non-linear
model.“子集选择”的概念可以应用于线性模型<em>之外</em>。</p></li>
</ul>
<h2
id="mathematical-understanding-key-questions-数学理解与关键问题">Mathematical
Understanding &amp; Key Questions 数学理解与关键问题</h2>
<p>This section directly answers the questions posed on your slides.</p>
<h3 id="how-to-compare-which-model-is-better">How to compare which model
is better?</h3>
<p>(From slides <code>...221320.png</code> and
<code>...221326.png</code>)</p>
<p>You cannot use <strong>training error</strong> (like <span
class="math inline">\(R^2\)</span> or RSS) to compare models with
<em>different numbers of predictors</em>. A model with more predictors
will almost always have a better <em>training</em> score, even if those
extra predictors are just noise. This is called
<strong>overfitting</strong>. 不能使用<strong>训练误差</strong>（例如
<span class="math inline">\(R^2\)</span> 或
RSS）来比较具有<em>不同数量预测变量</em>的模型。具有更多预测变量的模型几乎总是具有更好的<em>训练</em>分数，即使这些额外的预测变量只是噪声。这被称为<strong>过拟合</strong>。</p>
<p>To compare models of different sizes (like Model 1 vs. Model 2, or
<span class="math inline">\(M_2\)</span> vs. <span
class="math inline">\(M_5\)</span>), you <strong>must</strong> use a
method that estimates <strong>test error</strong> (how the model
performs on new, unseen data). The slides mention:
要比较不同大小的模型（例如模型 1 与模型 2，或 <span
class="math inline">\(M_2\)</span> 与 <span
class="math inline">\(M_5\)</span>），您<strong>必须</strong>使用一种估算<strong>测试误差</strong>（模型在新的、未见过的数据上的表现）的方法。</p>
<ul>
<li><p><strong>Cross-Validation (CV):</strong> This is the gold
standard. You split your data into “folds,” train the model on some
folds, and test it on the remaining fold. You repeat this and average
the test scores. The model with the best (e.g., lowest) average CV error
is chosen.
将数据分成“折叠”，在一些折叠上训练模型，然后在剩余的折叠上测试模型。重复此操作并取测试分数的平均值。选择平均
CV 误差最小（例如，最小）的模型。</p></li>
<li><p><strong>AIC &amp; BIC:</strong> These are mathematical
adjustments to the training error (like RSS) that add a <em>penalty</em>
for having more predictors. They balance model <em>fit</em> with model
<em>complexity</em>. 这些是对训练误差（如
RSS）的数学调整，会因预测变量较多而增加<em>惩罚</em>。它们平衡了模型<em>拟合度</em>和模型<em>复杂度</em>。</p></li>
</ul>
<h3 id="why-use-r2-in-step-2">Why use <span
class="math inline">\(R^2\)</span> in Step 2?</h3>
<p>(From slide <code>...221333.png</code>)</p>
<p>In Step 2, you are only comparing models <strong>of the same
size</strong> (i.e., all models that have exactly <span
class="math inline">\(k\)</span> predictors). For models with the same
number of parameters, a higher <span class="math inline">\(R^2\)</span>
(or lower RSS) on the training data directly corresponds to a better
fit. You don’t need to penalize for complexity because all models being
compared <em>have the same complexity</em>.
只比较<strong>大小相同</strong>的模型（即所有恰好具有 <span
class="math inline">\(k\)</span>
个预测变量的模型）。对于参数数量相同的模型，训练数据上更高的 <span
class="math inline">\(R^2\)</span>（或更低的
RSS）直接对应着更好的拟合度。您不需要对复杂度进行惩罚，因为所有被比较的模型<em>都具有相同的复杂度</em>。</p>
<h3 id="why-cant-we-use-training-error-in-step-3">Why can’t we use
training error in Step 3?</h3>
<p>(From slide <code>...221333.png</code>)</p>
<p>In Step 3, you are comparing models <strong>of different
sizes</strong> (<span class="math inline">\(M_0\)</span> vs. <span
class="math inline">\(M_1\)</span> vs. <span
class="math inline">\(M_2\)</span>, etc.). As you add predictors, the
training <span class="math inline">\(R^2\)</span> will <em>always</em>
go up (or stay the same), and the training RSS will <em>always</em> go
down (or stay the same). If you used <span
class="math inline">\(R^2\)</span> to pick the best model in Step 3, you
would <em>always</em> pick the most complex model <span
class="math inline">\(M_p\)</span>, which is almost certainly overfit.
将比较<strong>不同大小</strong>的模型（例如 <span
class="math inline">\(M_0\)</span> vs. <span
class="math inline">\(M_1\)</span> vs. <span
class="math inline">\(M_2\)</span> 等）。随着您添加预测变量，训练 <span
class="math inline">\(R^2\)</span>
将<em>始终</em>上升（或保持不变），而训练 RSS
将<em>始终</em>下降（或保持不变）。如果您在步骤 3 中使用 <span
class="math inline">\(R^2\)</span>
来选择最佳模型，那么您<em>始终</em>会选择最复杂的模型 <span
class="math inline">\(M_p\)</span>，而该模型几乎肯定会过拟合。</p>
<p>Therefore, you <em>must</em> use a metric that estimates test error
(like CV) or penalizes for complexity (like AIC, BIC, or Adjusted <span
class="math inline">\(R^2\)</span>) to find the right balance between
fit and simplicity. 因此，您<em>必须</em>使用一个可以估算测试误差（例如
CV）或惩罚复杂度（例如 AIC、BIC 或调整后的 <span
class="math inline">\(R^2\)</span>）的指标来找到拟合度和简单性之间的平衡。</p>
<h2 id="code-analysis">Code Analysis</h2>
<p>The Python code (slides <code>...221249.jpg</code> and
<code>...221303.jpg</code>) implements the <strong>Best Subset
Selection</strong> algorithm using <strong>KNN Regression</strong>.</p>
<h3 id="key-functions">Key Functions</h3>
<ul>
<li><code>main()</code>:
<ol type="1">
<li><strong>Loads Data:</strong> Reads the <code>Credit.csv</code>
file.</li>
<li><strong>Preprocesses Data:</strong>
<ul>
<li>Converts categorical features (‘Gender’, ‘Student’, ‘Married’,
‘Ethnicity’) into numerical ones (dummy variables).
将分类特征（“性别”、“学生”、“已婚”、“种族”）转换为数值特征（虚拟变量）。</li>
<li>Creates the feature matrix <code>X</code> and target variable
<code>y</code> (‘Balance’). 创建特征矩阵 <code>X</code> 和目标变量
<code>y</code>（“余额”）。</li>
<li><strong>Scales</strong> the features using
<code>StandardScaler</code>. This is crucial for KNN, which is sensitive
to the scale of features. 用 <code>StandardScaler</code>
对特征进行<strong>缩放</strong>。这对于 KNN
至关重要，因为它对特征的缩放非常敏感。</li>
</ul></li>
<li><strong>Adds Noise (in the second example):</strong> Slide
<code>...221303.jpg</code> shows code that <em>adds 20 new “noisy”
columns</em> to the data. This is to test if the selection algorithm is
smart enough to ignore them. 向数据中添加 20
个新的“噪声”列的代码。这是为了测试选择算法是否足够智能，能够忽略它们。</li>
<li><strong>Runs Selection:</strong> Calls
<code>best_subset_selection_parallel</code> to do the main work.</li>
<li><strong>Prints Results:</strong> Finds the best subset (lowest
error) and prints the top 20 best-performing subsets.
找到最佳子集（误差最小），并打印出表现最佳的前 20 个子集。</li>
<li><strong>Final Evaluation:</strong> It re-trains a KNN model on
<em>only</em> the best subset and calculates the final cross-validated
RMSE. 仅基于最佳子集重新训练 KNN 模型，并计算最终的交叉验证 RMSE。</li>
</ol></li>
<li><code>evaluate_subset(subset, ...)</code>:
<ul>
<li>This is the “worker” function. It’s called for <em>every single</em>
possible subset.</li>
<li>It takes a <code>subset</code> (a list of feature names, e.g.,
<code>['Income', 'Limit']</code>).</li>
<li>It creates a new <code>X_subset</code> containing <em>only</em>
those columns.</li>
<li>It runs 5-fold cross-validation (<code>cross_val_score</code>) on a
KNN model using this <code>X_subset</code>.</li>
<li>It uses <code>'neg_mean_squared_error'</code> as the metric. This is
negative MSE; a <em>higher</em> score (closer to 0) is better.
它会创建一个新的“X_subset”<em>，仅包含这些列。 它会使用此“X_subset”在
KNN 模型上运行 5 倍交叉验证（“cross_val_score”）。
它使用“neg_mean_squared_error”作为度量标准。这是负
MSE；</em>更高*的分数（越接近 0）越好。</li>
<li>It returns the subset and its average CV score.</li>
</ul></li>
<li><code>best_subset_selection_parallel(model, ...)</code>:
<ul>
<li>This is the “manager” function.这是“管理器”函数。</li>
<li>It iterates from <code>k=1</code> up to the total number of
features.它从“k=1”迭代到特征总数。</li>
<li>For each <code>k</code>, it generates <em>all combinations</em> of
features of that size (this is the <span
class="math inline">\(\binom{p}{k}\)</span> part).
对于每个“k”，它会生成该大小的特征的<em>所有组合</em>（这是 <span
class="math inline">\(\binom{p}{k}\)</span> 部分）。</li>
<li>It uses <code>Parallel</code> and <code>delayed</code> (from
<code>joblib</code>) to run <code>evaluate_subset</code> for all these
combinations <em>in parallel</em>, speeding up the process
significantly. 它使用 <code>Parallel</code> 和
<code>delayed</code>（来自
<code>joblib</code>）对所有这些组合<em>并行</em>运行
<code>evaluate_subset</code>，从而显著加快了处理速度。</li>
<li>It collects all the results and returns
them.它收集所有结果并返回。</li>
</ul></li>
</ul>
<h3 id="analysis-of-the-output">Analysis of the Output</h3>
<ul>
<li><strong>Slide <code>...221255.png</code> (Original Data):</strong>
<ul>
<li>The code runs subset selection on the original dataset.</li>
<li>The “Top 20 Best Feature Subsets” are shown. The CV scores are
negative (they are <code>neg_mean_squared_error</code>), so the scores
<em>closest to zero</em> (smallest magnitude) are best.</li>
<li>The <strong>Best feature subset</strong> is found to be
<code>('Income', 'Limit', 'Rating', 'Student')</code>.</li>
<li>The final cross-validated RMSE for this model is
<strong>105.41</strong>.</li>
</ul></li>
<li><strong>Slide <code>...221309.png</code> (Data with 20 Noisy
Variables):</strong>
<ul>
<li>The code is re-run after adding 20 useless “Noisy” features.</li>
<li>The algorithm <em>still</em> works. It correctly identifies that the
“Noisy” variables are useless.</li>
<li>The <strong>Best feature subset</strong> is now
<code>('Income', 'Limit', 'Student')</code>. (Note: ‘Rating’ was
dropped, likely because it’s highly correlated with ‘Limit’, and the
noisy data made the simpler model perform slightly better in CV).</li>
<li>The final RMSE is <strong>114.94</strong>. This is <em>higher</em>
than the original 105.41, which is expected—the presence of so many
noise variables makes the selection problem harder, but the final model
is still good and, most importantly, <em>it successfully excluded all 20
noisy features</em>. 最终的 RMSE 为 <strong>114.94</strong>。这比最初的
105.41<em>更高</em>，这是预期的——如此多的噪声变量的存在使得选择问题更加困难，但最终模型仍然很好，最重要的是，<em>它成功地排除了所有
20 个噪声特征</em>。</li>
</ul></li>
</ul>
<h2 id="conceptual-overview-the-why">Conceptual Overview: The “Why”</h2>
<p>Slides cover <strong>Chapter 6: Linear Model Selection and
Regularization</strong>, which is all about a fundamental trade-off in
machine learning: the <strong>bias-variance trade-off</strong>.
该部分主要讨论机器学习中的一个基本权衡：<strong>偏差-方差权衡</strong>。</p>
<ul>
<li><p><strong>The Problem (Slide <code>...221320.png</code>):</strong>
Imagine you have a dataset with 50 predictors (<span
class="math inline">\(p=50\)</span>). You want to predict a response
<span class="math inline">\(y\)</span>. 假设你有一个包含 50
个预测变量（p=50）的数据集。你想要预测响应 <span
class="math inline">\(y\)</span>。</p>
<ul>
<li><strong>Model 1 (Full Model):</strong> You use all 50 predictors.
This model is very <strong>flexible</strong>. It will fit the
<em>training data</em> extremely well, resulting in a low
<strong>bias</strong>. However, it’s highly likely that many of those 50
predictors are just “noise” (random, unrelated variables). By fitting to
this noise, the model will be <strong>overfit</strong>. When you show it
new, unseen data (the <em>test data</em>), it will perform poorly. This
is called <strong>high variance</strong>. 你使用了所有 50
个预测变量。这个模型非常<strong>灵活</strong>。它能很好地拟合<em>训练数据</em>，从而产生较低的<strong>偏差</strong>。然而，这
50
个预测变量中很可能有很多只是“噪声”（随机的、不相关的变量）。由于拟合这些噪声，模型会<strong>过拟合</strong>。当你向它展示新的、未见过的数据（<em>测试数据</em>）时，它的表现会很差。这被称为<strong>高方差</strong>。</li>
<li><strong>Model 2 (Subset Model):</strong> You intelligently select
only the 3 predictors (<span class="math inline">\(q=3\)</span>) that
are <em>actually</em> related to <span class="math inline">\(y\)</span>.
This model is less flexible. It won’t fit the <em>training data</em> as
perfectly as Model 1 (it has higher <strong>bias</strong>). But, because
it’s <em>not</em> fitting the noise, it will generalize much better to
new data. It will have a much lower <strong>variance</strong>, and thus
a lower overall <em>test error</em>. 你智能地只选择与 <span
class="math inline">\(y\)</span> <em>真正</em>相关的 3 个预测变量 (<span
class="math inline">\(q=3\)</span>)。这个模型的灵活性较差。它对
<em>训练数据</em> 的拟合度不如模型 1
完美（它的<strong>偏差</strong>更高）。但是，由于它对噪声的拟合度更高，因此对新数据的泛化能力会更好。它的<strong>方差</strong>会更低，因此总体的<em>测试误差</em>也会更低。</li>
</ul></li>
<li><p><strong>The Goal:</strong> The goal is to find the model that has
the <strong>lowest test error</strong>. We need a formal method to
<em>find</em> the best subset (like Model 2) without just guessing.
<strong>目标是找到</strong>测试误差**最低的模型。我们需要一个正式的方法来<em>找到</em>最佳子集（例如模型
2），而不是仅仅靠猜测。</p></li>
<li><p><strong>Two Main Strategies (Slide
<code>...221314.png</code>):</strong></p>
<ol type="1">
<li><p><strong>Subset Selection (Section 6.1):</strong> This is what
we’re focused on. It’s an “all-or-nothing” approach. You either
<em>keep</em> a variable in the model or you <em>discard</em> it
completely. The “Best Subset Selection” algorithm is the most extreme,
“brute-force” way to do this.
是我们关注的重点。这是一种“全有或全无”的方法。你要么在模型中“保留”一个变量，要么“彻底丢弃”它。“最佳子集选择”算法是最极端、最“暴力”的做法。</p></li>
<li><p><strong>Shrinkage/Regularization (Section 6.2):</strong> This is
a more subtle approach (e.g., Ridge Regression, LASSO). Instead of
discarding variables, you <em>keep all <span
class="math inline">\(p\)</span> variables</em> but add a penalty to the
model that “shrinks” the coefficients (<span
class="math inline">\(\beta\)</span>) of the useless variables towards
zero.
这是一种更巧妙的方法（例如，岭回归、LASSO）。你不是丢弃变量，而是<em>保留所有
<span class="math inline">\(p\)</span>
个变量</em>，但会给模型添加一个惩罚项，将无用变量的系数（<span
class="math inline">\(\beta\)</span>）“收缩”到零。</p></li>
</ol></li>
</ul>
<h2 id="questions">Questions 🎯</h2>
<h3 id="q1-how-to-compare-which-model-is-better">Q1: “How to compare
which model is better?”</h3>
<p>(From slides <code>...221320.png</code> and
<code>...221326.png</code>)</p>
<p>This is the most important question. You <strong>cannot</strong> use
metrics based on <em>training data</em> (like <span
class="math inline">\(R^2\)</span> or RSS - Residual Sum of Squares) to
compare models with <em>different numbers of predictors</em>.
这是最重要的问题。您<strong>不能</strong>使用基于<em>训练数据</em>的指标（例如
R^2 或 RSS - 残差平方和）来比较具有<em>不同数量预测变量</em>的模型。</p>
<ul>
<li><p><strong>The Trap:</strong> A model with more predictors will
<em>always</em> have a higher <span class="math inline">\(R^2\)</span>
(or lower RSS) on the data it was trained on. <span
class="math inline">\(R^2\)</span> will <em>always</em> increase as you
add variables, even if they are pure noise. If you used <span
class="math inline">\(R^2\)</span> to compare a 3-predictor model to a
10-predictor model, the 10-predictor model would <em>always</em> look
better on paper, even if it’s terribly overfit.
具有更多预测变量的模型在其训练数据上<em>总是</em>具有更高的
R^2（或更低的 RSS）。随着变量的增加，R^2
会<em>总是</em>增加，即使这些变量是纯噪声。如果您使用 R^2 来比较 3
个预测变量的模型和 10 个预测变量的模型，那么 10
个预测变量的模型在纸面上<em>总是</em>看起来更好，即使它严重过拟合。</p></li>
<li><p><strong>The Correct Way:</strong> You must use a metric that
estimates the <strong>test error</strong>. The slides and code show two
ways:您必须使用一个能够估计<strong>测试误差</strong>的指标。</p>
<ol type="1">
<li><strong>Cross-Validation (CV):</strong> This is the method used in
your Python code. It works by:
<ul>
<li>Splitting your training data into <span
class="math inline">\(k\)</span> “folds” (e.g., 5 folds).
将训练数据拆分成 <span class="math inline">\(k\)</span> 个“折叠”（例如 5
个折叠）。</li>
<li>Training the model on 4 folds and testing it on the 5th fold.
使用其中 4 个折叠训练模型，并使用第 5 个折叠进行测试。</li>
<li>Repeating this 5 times, so each fold gets to be the test set once.
重复此操作 5 次，使每个折叠都作为测试集一次。</li>
<li>Averaging the 5 test errors. 对 5 个测试误差求平均值。 This gives
you a robust estimate of how your model will perform on <em>unseen
data</em>. You then choose the model with the best (lowest) average CV
error.
这可以让你对模型在<em>未见数据</em>上的表现有一个稳健的估计。然后，你可以选择平均
CV 误差最小（最佳）的模型。</li>
</ul></li>
<li><strong>Mathematical Adjustments (AIC, BIC, Adjusted <span
class="math inline">\(R^2\)</span>):</strong> These are formulas that
take the training error (like RSS) and add a <em>penalty</em> for each
predictor (<span class="math inline">\(k\)</span>) you add.
<ul>
<li><span class="math inline">\(AIC \approx RSS +
2k\sigma^2\)</span></li>
<li><span class="math inline">\(BIC \approx RSS +
\log(n)k\sigma^2\)</span> A model with more predictors (larger <span
class="math inline">\(k\)</span>) gets a bigger penalty. To be chosen, a
more complex model must <em>significantly</em> improve the RSS to
overcome this penalty. 预测变量越多（k
越大）的模型，惩罚越大。要被选中，更复杂的模型必须<em>显著</em>提升 RSS
以克服此惩罚。</li>
</ul></li>
</ol></li>
</ul>
<h3 id="q2-why-using-r2-for-step-2">Q2: “Why using <span
class="math inline">\(R^2\)</span> for step 2?”</h3>
<p>(From slide <code>...221333.png</code>)</p>
<p><strong>Step 2</strong> of the “Best Subset Selection” algorithm
says: “For <span class="math inline">\(k = 1, \dots, p\)</span>: Fit all
<span class="math inline">\(\binom{p}{k}\)</span> models… Pick the best
model, that with the largest <span class="math inline">\(R^2\)</span>, …
and call it <span class="math inline">\(M_k\)</span>.” “对于 <span
class="math inline">\(k = 1, \dots, p\)</span>：拟合所有 <span
class="math inline">\(\binom{p}{k}\)</span> 个模型……选择具有最大 <span
class="math inline">\(R^2\)</span> 的最佳模型……并将其命名为 <span
class="math inline">\(M_k\)</span>。”</p>
<ul>
<li><strong>The Reason:</strong> In Step 2, you are <em>only</em>
comparing models <strong>of the same size</strong>. For example, when
<span class="math inline">\(k=3\)</span>, you are comparing all possible
3-predictor models: 步骤 2
中，您<em>仅</em>比较**相同大小的模型。例如，当 <span
class="math inline">\(k=3\)</span> 时，您将比较所有可能的 3
预测变量模型：
<ul>
<li>Model A: (<span class="math inline">\(X_1, X_2, X_3\)</span>)</li>
<li>Model B: (<span class="math inline">\(X_1, X_2, X_4\)</span>)</li>
<li>Model C: (<span class="math inline">\(X_1, X_3, X_5\)</span>)</li>
<li>…and so on.</li>
</ul>
Since all these models have the <em>exact same complexity</em> (they all
have <span class="math inline">\(k=3\)</span> predictors), there is no
risk of unfairly favoring a more complex model. Therefore, you are free
to use a training metric like <span class="math inline">\(R^2\)</span>
(or RSS). The model with the highest <span
class="math inline">\(R^2\)</span> is, by definition, the one that
<em>best fits the training data</em> for that specific size <span
class="math inline">\(k\)</span>.
由于所有这些模型都具有<em>完全相同的复杂度</em>（它们都具有 <span
class="math inline">\(k=3\)</span>
个预测变量），因此不存在不公平地偏向更复杂模型的风险。因此，您可以自由使用像
<span class="math inline">\(R^2\)</span>（或
RSS）这样的训练指标。根据定义，具有最高 <span
class="math inline">\(R^2\)</span> 的模型就是在特定大小 <span
class="math inline">\(k\)</span>
下<em>与训练数据拟合度</em>最高的模型。</li>
</ul>
<h3
id="q3-cannot-use-training-error-in-step-3.-why-not-步骤-3-中不能使用训练误差-为什么">Q3:
“Cannot use training error in Step 3.” Why not? “步骤 3
中不能使用训练误差。” 为什么？</h3>
<p>(From slide <code>...221333.png</code>)</p>
<p><strong>Step 3</strong> says: “Select a single best model from <span
class="math inline">\(M_0, M_1, \dots, M_p\)</span> by cross validation,
AIC, or BIC.”“通过交叉验证、AIC 或 BIC，从 <span
class="math inline">\(M_0、M_1、\dots、M_p\)</span>
中选择一个最佳模型。”</p>
<ul>
<li><p><strong>The Reason:</strong> In Step 3, you are now comparing
models <strong>of different sizes</strong>. You are comparing the best
1-predictor model (<span class="math inline">\(M_1\)</span>) vs. the
best 2-predictor model (<span class="math inline">\(M_2\)</span>)
vs. the best 3-predictor model (<span
class="math inline">\(M_3\)</span>), and so on, all the way up to <span
class="math inline">\(M_p\)</span>. 在步骤 3
中，您正在比较<strong>不同大小</strong>的模型。您正在比较最佳的单预测模型
(<span class="math inline">\(M_1\)</span>)、最佳的双预测模型 (<span
class="math inline">\(M_2\)</span>) 和最佳的三预测模型 (<span
class="math inline">\(M_3\)</span>)，依此类推，直到 <span
class="math inline">\(M_p\)</span>。</p>
<p>As explained in Q1, if you used a training error metric like <span
class="math inline">\(R^2\)</span> here, the <span
class="math inline">\(R^2\)</span> would just keep going up, and you
would <em>always</em> select the largest, most complex model, <span
class="math inline">\(M_p\)</span>. This completely defeats the purpose
of model selection. 如问题 1 所述，如果您在此处使用像 <span
class="math inline">\(R^2\)</span> 这样的训练误差指标，那么 <span
class="math inline">\(R^2\)</span>
会持续上升，并且您<em>总是</em>会选择最大、最复杂的模型 <span
class="math inline">\(M_p\)</span>。这完全违背了模型选择的目的。</p>
<p>Therefore, in Step 3, you <em>must</em> use a method that estimates
<strong>test error</strong> (like Cross-Validation) or one that
<strong>penalizes for complexity</strong> (like AIC or BIC) to find the
“sweet spot” model that balances fit and simplicity. 因此，在步骤 3
中，您<em>必须</em>使用一种估算<strong>测试误差</strong>的方法（例如交叉验证）或<strong>惩罚复杂性</strong>的方法（例如
AIC 或
BIC），以找到在拟合度和简单性之间取得平衡的“最佳点”模型。</p></li>
</ul>
<h2 id="mathematical-deep-dive">Mathematical Deep Dive 🧮</h2>
<ul>
<li><strong><span class="math inline">\(Y = \beta_0 + \beta_1X_1 + \dots
+ \beta_pX_p + \epsilon\)</span>:</strong> The full linear model. The
goal of subset selection is to find a subset of <span
class="math inline">\(X_j\)</span>’s where <span
class="math inline">\(\beta_j \neq 0\)</span> and set all other <span
class="math inline">\(\beta\)</span>’s to 0.
完整的线性模型。子集选择的目标是找到 <span
class="math inline">\(X_j\)</span> 的一个子集，其中 $_j 等于
0，并将所有其他 <span class="math inline">\(\beta\)</span> 设置为
0。</li>
<li><strong><span class="math inline">\(2^p\)</span>
combinations:</strong> (Slide <code>...221333.png</code>) This is the
total number of models you have to check. For each of the <span
class="math inline">\(p\)</span> variables, you have two choices: either
it is <strong>IN</strong> the model or it is
<strong>OUT</strong>.这是你需要检查的模型总数。对于每个 <span
class="math inline">\(p\)</span>
个变量，你有两个选择：要么它在模型<strong>内部</strong>，要么它在模型<strong>外部</strong>。
<ul>
<li>Example: <span class="math inline">\(p=3\)</span> (variables <span
class="math inline">\(X_1, X_2, X_3\)</span>)</li>
<li>The <span class="math inline">\(2^3 = 8\)</span> possible models
are:
<ol type="1">
<li>{} (The null model, <span class="math inline">\(M_0\)</span>)</li>
<li>{ <span class="math inline">\(X_1\)</span> }</li>
<li>{ <span class="math inline">\(X_2\)</span> }</li>
<li>{ <span class="math inline">\(X_3\)</span> }</li>
<li>{ <span class="math inline">\(X_1, X_2\)</span> }</li>
<li>{ <span class="math inline">\(X_1, X_3\)</span> }</li>
<li>{ <span class="math inline">\(X_2, X_3\)</span> }</li>
<li>{ <span class="math inline">\(X_1, X_2, X_3\)</span> } (The full
model, <span class="math inline">\(M_3\)</span>)</li>
</ol></li>
<li>This is why this method is called an <strong>“exhaustive
search”</strong>. It literally checks every single one. For <span
class="math inline">\(p=20\)</span>, <span
class="math inline">\(2^{20}\)</span> is over a million
models!这就是该方法被称为<strong>“穷举搜索”</strong>的原因。它实际上会检查每一个模型。对于
<span class="math inline">\(p=20\)</span>，<span
class="math inline">\(2^{20}\)</span> 就超过一百万个模型！</li>
</ul></li>
<li><strong><span class="math inline">\(\binom{p}{k} =
\frac{p!}{k!(p-k)!}\)</span>:</strong> (Slide
<code>...221333.png</code>) This is the “combinations” formula. It tells
you <em>how many</em> models you fit <em>in Step 2</em> for a specific
<span
class="math inline">\(k\)</span>.这是“组合”公式。它告诉你，对于特定的
<span class="math inline">\(k\)</span>，<em>在步骤 2</em>中，你拟合了
<em>多少</em> 个模型。
<ul>
<li>Example: <span class="math inline">\(p=10\)</span> total
predictors.</li>
<li>For <span class="math inline">\(k=1\)</span>: You fit <span
class="math inline">\(\binom{10}{1} = 10\)</span> models.</li>
<li>For <span class="math inline">\(k=2\)</span>: You fit <span
class="math inline">\(\binom{10}{2} = \frac{10 \times 9}{2 \times 1} =
45\)</span> models.</li>
<li>For <span class="math inline">\(k=3\)</span>: You fit <span
class="math inline">\(\binom{10}{3} = \frac{10 \times 9 \times 8}{3
\times 2 \times 1} = 120\)</span> models.</li>
<li>…and so on. The sum of all these <span
class="math inline">\(\binom{p}{k}\)</span> from <span
class="math inline">\(k=0\)</span> to <span
class="math inline">\(k=p\)</span> equals <span
class="math inline">\(2^p\)</span>.</li>
</ul></li>
</ul>
<h2 id="detailed-code-analysis">Detailed Code Analysis 💻</h2>
<p>Your slides show Python code that applies the <strong>Best Subset
Selection algorithm</strong> to a <strong>KNN Regressor</strong>. This
is a great example of how the <em>selection algorithm</em> is
independent of the <em>model type</em> (as mentioned in slide
<code>...221314.png</code>).</p>
<h3 id="key-functions-1">Key Functions</h3>
<ul>
<li><strong><code>main()</code></strong>
<ol type="1">
<li><strong>Load &amp; Preprocess:</strong> Reads
<code>Credit.csv</code>. The most important step here is converting
categorical text (like ‘Male’/‘Female’) into numbers (1/0).</li>
<li><strong>Scale Data:</strong> <code>scaler = StandardScaler()</code>
and <code>X_scaled = scaler.fit_transform(X)</code>.
<ul>
<li><strong>WHY?</strong> This is <strong>CRITICAL</strong> for KNN. KNN
works by measuring distance. If ‘Income’ (e.g., 50,000) is on a vastly
different scale than ‘Cards’ (e.g., 3), the ‘Income’ feature will
completely dominate the distance calculation, making ‘Cards’ irrelevant.
Scaling resizes all features to have a mean of 0 and standard deviation
of 1, so they all contribute fairly.</li>
</ul></li>
<li><strong>Handle Noisy Data (Slide
<code>...221303.jpg</code>):</strong> This version of the code
<em>intentionally</em> adds 20 columns of useless, random numbers. This
is a test to see if the algorithm is smart enough to ignore them.</li>
<li><strong>Run Selection:</strong>
<code>results_df = best_subset_selection_parallel(...)</code>. This
function does all the heavy lifting (explained next).</li>
<li><strong>Find Best Model:</strong>
<code>results_df.sort_values(by='CV_Score', ascending=False)</code>.
<ul>
<li><strong>WHY <code>ascending=False</code>?</strong> The code uses the
metric <code>'neg_mean_squared_error'</code>. This is MSE, but negative
(e.g., -15000). A <em>better</em> model has an error closer to 0 (e.g.,
-10000). Since -10000 is <em>greater than</em> -15000, you sort in
descending (high-to-low) order to put the best models at the top.</li>
</ul></li>
<li><strong>Final Evaluation (Step 3):</strong>
<code>final_scores = cross_val_score(knn, X_best, y, ...)</code>
<ul>
<li>This is the implementation of Step 3. It takes <em>only</em> the
single best subset (<code>X_best</code>) and runs a <em>new</em>
cross-validation on it. This gives a final, unbiased estimate of how
good that one model is.</li>
</ul></li>
<li><strong>Print RMSE:</strong>
<code>final_rmse = np.sqrt(-final_scores)</code>. It converts the
negative MSE back into a positive RMSE (Root Mean Squared Error), which
is in the same units as the target <span
class="math inline">\(y\)</span> (in this case, ‘Balance’ in
dollars).</li>
</ol></li>
<li><strong><code>best_subset_selection_parallel(model, ...)</code></strong>
<ol type="1">
<li>This is the “manager” function. It implements the loop from Step
2.</li>
<li><code>for k in range(1, n_features + 1):</code> This is the loop
“For <span class="math inline">\(k = 1, \dots, p\)</span>”.</li>
<li><code>subsets = list(combinations(feature_names, k))</code>: This
generates the <span class="math inline">\(\binom{p}{k}\)</span>
combinations for the current <span
class="math inline">\(k\)</span>.</li>
<li><code>results = Parallel(n_jobs=n_jobs)(...)</code>: This is a
non-core, “speed-up” command. It uses the <code>joblib</code> library to
run the evaluations on all your computer’s CPU cores at once (in
parallel). Without this, checking millions of models would take
days.</li>
<li><code>subset_scores = ... [delayed(evaluate_subset)(...) ...]</code>
This line farms out the <em>actual work</em> to the
<code>evaluate_subset</code> function for every single subset.</li>
</ol></li>
<li><strong><code>evaluate_subset(subset, ...)</code></strong>
<ol type="1">
<li>This is the “worker” function. It gets called thousands or millions
of times.</li>
<li>Its job is to evaluate <em>one single subset</em> (e.g.,
<code>('Income', 'Limit', 'Student')</code>).</li>
<li><code>X_subset = X[list(subset)]</code>: It slices the data to get
<em>only</em> these columns.</li>
<li><code>scores = cross_val_score(model, X_subset, ...)</code>:
<strong>This is the most important line.</strong> It takes the subset
and performs a full 5-fold cross-validation on it.</li>
<li><code>return (subset, np.mean(scores))</code>: It returns the subset
and its average CV score.</li>
</ol></li>
</ul>
<h3 id="summary-of-outputs-slides-...221255.png-...221309.png">Summary
of Outputs (Slides <code>...221255.png</code> &amp;
<code>...221309.png</code>)</h3>
<ul>
<li><strong>Original Data (Slide <code>...221255.png</code>):</strong>
<ul>
<li><strong>Best Subset:</strong>
<code>('Income', 'Limit', 'Rating', 'Student')</code></li>
<li><strong>Final RMSE:</strong> ~105.4</li>
</ul></li>
<li><strong>Data with 20 “Noisy” Variables (Slide
<code>...221309.png</code>):</strong>
<ul>
<li><strong>Best Subset:</strong>
<code>('Income', 'Limit', 'Student')</code></li>
<li><strong>Result:</strong> The algorithm <em>successfully</em>
identified that all 20 “Noisy” variables were useless and
<strong>excluded every single one of them</strong> from the best
models.</li>
<li><strong>Final RMSE:</strong> ~114.9</li>
<li><strong>Key Takeaway:</strong> The RMSE is slightly higher, which
makes sense because the selection problem was much harder. But the
<em>method worked perfectly</em>. It filtered all the “noise” and found
a simple, powerful model, just as the theory on slide
<code>...221320.png</code> predicted.</li>
</ul></li>
</ul>
<h1
id="the-core-problem-training-error-vs.-test-error-核心问题训练误差-vs.-测试误差">2.
The Core Problem: Training Error vs. Test Error 核心问题：训练误差
vs. 测试误差</h1>
<p>The central theme of these slides is finding the “best” model. The
problem is that a model with more predictors (more complex) will
<em>always</em> fit the data it was trained on better. This is a trap.
寻找“最佳”模型。问题在于，预测因子越多（越复杂）的模型<em>总是</em>能更好地拟合训练数据。这是一个陷阱。</p>
<ul>
<li><strong>Training Error:</strong> How well the model fits the data we
used to build it. <strong><span class="math inline">\(R^2\)</span> and
<span class="math inline">\(RSS\)</span> measure this.</strong>
模型与我们构建模型时所用数据的拟合程度。<strong><span
class="math inline">\(R^2\)</span> 和 <span
class="math inline">\(RSS\)</span> 衡量了这一点。</strong></li>
<li><strong>Test Error:</strong> How well the model predicts new, unseen
data. This is what we <em>actually</em> care about. A model that is too
complex (e.g., has 10 predictors when only 3 are useful) will have low
training error but very high test error. This is called
<strong>overfitting</strong>.
模型预测新的、未见过的数据的准确程度。这才是我们<em>真正</em>关心的。过于复杂的模型（例如，有
10 个预测因子，但只有 3
个有用）的训练误差会很低，但测试误差会很高。这被称为<strong>过拟合</strong>。</li>
</ul>
<p>The goal is to choose a model that has the lowest <em>test
error</em>. The metrics below (Adjusted <span
class="math inline">\(R^2\)</span>, AIC, BIC) are all attempts to
<em>estimate</em> this test error without having to actually collect new
data. They do this by adding a <strong>penalty</strong> for complexity.
目标是选择一个具有最低<em>测试误差</em>的模型。以下指标（调整后的 <span
class="math inline">\(R^2\)</span>、AIC、BIC）都是在无需实际收集新数据的情况下尝试<em>估计</em>此测试误差。他们通过增加<strong>复杂度惩罚</strong>来实现这一点。</p>
<h2 id="basic-metrics-measures-of-fit">Basic Metrics (Measures of
Fit)</h2>
<p>These formulas from slide 13 describe how well a model fits the
<em>training data</em>.</p>
<h3 id="residue-error-残差误差">Residue (Error) 残差（误差）</h3>
<ul>
<li><strong>Formula:</strong> <span
class="math inline">\(\hat{\epsilon}_i = y_i - \hat{y}_i = y_i -
\hat{\beta}_0 - \sum_{j=1}^{p} \hat{\beta}_j x_{ij}\)</span></li>
<li><strong>Concept:</strong> This is the most basic building block.
It’s the difference between the <em>actual</em> observed value (<span
class="math inline">\(y_i\)</span>) and the value your model
<em>predicted</em> (<span class="math inline">\(\hat{y}_i\)</span>). It
is the “error” for a single data point.
这是最基本的构建块。它是<em>实际</em>观测值 (<span
class="math inline">\(y_i\)</span>) 与模型*预测值 (<span
class="math inline">\(\hat{y}_i\)</span>)
之间的差值。它是单个数据点的“误差”。</li>
</ul>
<h3 id="residual-sum-of-squares-rss-残差平方和-rss">Residual Sum of
Squares (RSS) 残差平方和 (RSS)</h3>
<ul>
<li><strong>Formula:</strong> <span class="math inline">\(RSS =
\sum_{i=1}^{n} \hat{\epsilon}_i^2\)</span></li>
<li><strong>Concept:</strong> This is the overall measure of model
error. You square all the individual errors (residues) to make them
positive and then add them all up.
这是模型误差的总体度量。将所有单个误差（残差）平方，使其为正，然后将它们全部相加。</li>
<li><strong>Goal:</strong> The entire process of linear regression
(called “Ordinary Least Squares”) is designed to find the <span
class="math inline">\(\hat{\beta}\)</span> coefficients that make this
<strong>RSS value as small as possible</strong>.
整个线性回归过程（称为“普通最小二乘法”）旨在找到使<strong>RSS
值尽可能小</strong>的 <span class="math inline">\(\hat{\beta}\)</span>
个系数。</li>
<li><strong>The Flaw 缺陷:</strong> <span
class="math inline">\(RSS\)</span> will <em>always</em> decrease (or
stay the same) as you add more predictors (<span
class="math inline">\(p\)</span>). A model with all 10 predictors will
have a lower <span class="math inline">\(RSS\)</span> than a model with
9, even if that 10th predictor is useless. Therefore, <span
class="math inline">\(RSS\)</span> is useless for choosing
<em>between</em> models of different sizes. 随着预测变量 (<span
class="math inline">\(p\)</span>) 的增加，<span
class="math inline">\(RSS\)</span>
总是会减小（或保持不变）。一个包含所有 10 个预测变量的模型的 <span
class="math inline">\(RSS\)</span> 会低于一个包含 9
个预测变量的模型，即使第 10 个预测变量毫无用处。因此，<span
class="math inline">\(RSS\)</span>
对于在不同规模的模型之间进行选择毫无用处。</li>
</ul>
<h3 id="r-squared-r2">R-squared (<span
class="math inline">\(R^2\)</span>)</h3>
<ul>
<li><strong>Formula:</strong> <span class="math inline">\(R^2 = 1 -
\frac{SS_{error}}{SS_{total}} = 1 - \frac{RSS}{\sum_{i=1}^{n} (y_i -
\bar{y})^2}\)</span></li>
<li><strong>Concept:</strong> This metric reframes <span
class="math inline">\(RSS\)</span> into a more interpretable
percentage.此指标将 <span class="math inline">\(RSS\)</span>
重新定义为更易于解释的百分比。
<ul>
<li><span class="math inline">\(SS_{total}\)</span> (the denominator)
represents the <em>total variance</em> of the data. It’s the error you
would get if your “model” was just guessing the average value (<span
class="math inline">\(\bar{y}\)</span>) for every single observation.
（分母）表示数据的<em>总方差</em>。如果你的“模型”只是猜测每个观测值的平均值
(<span
class="math inline">\(\bar{y}\)</span>)，那么你就会得到这个误差。</li>
<li><span class="math inline">\(SS_{error}\)</span> (the <span
class="math inline">\(RSS\)</span>) is the error <em>after</em> using
your model. 是“模型解释的总方差的比例”。 <span
class="math inline">\(R^2\)</span> 为 0.75
意味着你的模型可以解释响应变量 75% 的变异。</li>
<li><span class="math inline">\(R^2\)</span> is the “proportion of total
variance explained by the model.” An <span
class="math inline">\(R^2\)</span> of 0.75 means your model can explain
75% of the variation in the response variable.</li>
</ul></li>
<li><strong>The Flaw 缺陷:</strong> Just like <span
class="math inline">\(RSS\)</span>, <span
class="math inline">\(R^2\)</span> will <em>always</em> increase (or
stay the same) as you add more predictors. This is visually confirmed in
Figure 6.1, where the red line for <span
class="math inline">\(R^2\)</span> only goes up. It will always pick the
most complex model. 与 <span class="math inline">\(RSS\)</span>
一样，随着预测变量的增加，<span class="math inline">\(R^2\)</span>
会<em>始终</em>增加（或保持不变）。图 6.1 直观地证实了这一点，其中 <span
class="math inline">\(R^2\)</span>
的红线只会上升。它总是会选择最复杂的模型。</li>
</ul>
<h2
id="advanced-metrics-for-model-selection-高级指标用于模型选择">Advanced
Metrics (For Model Selection) 高级指标（用于模型选择）</h2>
<p>These metrics “fix” the flaw of <span
class="math inline">\(R^2\)</span> by including a penalty for the number
of predictors.</p>
<h3 id="adjusted-r2">Adjusted <span
class="math inline">\(R^2\)</span></h3>
<ul>
<li><strong>Formula:</strong> <span class="math display">\[
  \text{Adjusted } R^2 = 1 - \frac{RSS / (n - p - 1)}{SS_{total} / (n -
1)}
  \]</span></li>
<li><strong>Mathematical Concept:</strong> This formula replaces the
“Sum of Squares” (<span class="math inline">\(SS\)</span>) with “Mean
Squares” (<span class="math inline">\(MS\)</span>).
<ul>
<li><span class="math inline">\(MS_{error} =
\frac{RSS}{n-p-1}\)</span></li>
<li><span class="math inline">\(MS_{total} =
\frac{SS_{total}}{n-1}\)</span></li>
</ul></li>
<li><strong>The “Penalty” Explained:</strong> The penalty is
<strong>degrees of freedom</strong>.
<ul>
<li><span class="math inline">\(n\)</span> = number of data points.</li>
<li><span class="math inline">\(p\)</span> = number of predictors.</li>
<li>The term <span class="math inline">\(n-p-1\)</span> is the degrees
of freedom for the residuals. You start with <span
class="math inline">\(n\)</span> data points, but you “use up” one
degree of freedom to estimate the intercept (<span
class="math inline">\(\hat{\beta}_0\)</span>) and <span
class="math inline">\(p\)</span> more to estimate the <span
class="math inline">\(p\)</span> slopes.</li>
</ul></li>
<li><strong>How it Works:</strong>
<ol type="1">
<li>When you add a new predictor (increase <span
class="math inline">\(p\)</span>), <span
class="math inline">\(RSS\)</span> goes down, which makes the numerator
(<span class="math inline">\(MS_{error}\)</span>) smaller.</li>
<li>…But, increasing <span class="math inline">\(p\)</span>
<em>also</em> decreases the denominator (<span
class="math inline">\(n-p-1\)</span>), which makes the numerator (<span
class="math inline">\(MS_{error}\)</span>) <em>larger</em>.</li>
</ol>
<ul>
<li>This creates a “tug-of-war.” If the new predictor is
<strong>useful</strong>, it will drop <span
class="math inline">\(RSS\)</span> a lot, and Adjusted <span
class="math inline">\(R^2\)</span> will <strong>increase</strong>. If
the new predictor is <strong>useless</strong>, <span
class="math inline">\(RSS\)</span> will barely change, and the penalty
from decreasing the denominator will win, causing Adjusted <span
class="math inline">\(R^2\)</span> to <strong>decrease</strong>.</li>
</ul></li>
<li><strong>Goal:</strong> You select the model with the
<strong>highest</strong> Adjusted <span
class="math inline">\(R^2\)</span>.</li>
</ul>
<h3 id="akaike-information-criterion-aic">Akaike Information Criterion
(AIC)</h3>
<ul>
<li><strong>General Formula:</strong> <span class="math inline">\(AIC =
-2 \log \ell(\hat{\theta}) + 2d\)</span></li>
<li><strong>Concept Breakdown:</strong>
<ul>
<li><span class="math inline">\(\ell(\hat{\theta})\)</span>: This is the
<strong>Maximized Likelihood Function</strong>.
<ul>
<li>The <strong>Likelihood Function</strong> <span
class="math inline">\(\ell(\theta)\)</span> asks: “Given a set of model
parameters <span class="math inline">\(\theta\)</span>, how probable is
the data we observed?”</li>
<li>The <strong>Maximum Likelihood Estimate (MLE)</strong> <span
class="math inline">\(\hat{\theta}\)</span> is the specific set of
parameters (the <span class="math inline">\(\hat{\beta}\)</span>’s) that
<em>maximizes</em> this probability.</li>
</ul></li>
<li><span class="math inline">\(\log \ell(\hat{\theta})\)</span>: The
<strong>log-likelihood</strong>. This is just a number that represents
the <em>best possible fit</em> the model can achieve for the data. A
higher number is a better fit.</li>
<li><span class="math inline">\(-2 \log \ell(\hat{\theta})\)</span>:
This is the <strong>Deviance</strong>. Since a higher log-likelihood is
better, a <em>lower</em> deviance is better. This term measures
<strong>poorness-of-fit</strong>.</li>
<li><span class="math inline">\(d\)</span>: The number of parameters
estimated by the model. (e.g., <span class="math inline">\(p\)</span>
predictors + 1 intercept).</li>
<li><span class="math inline">\(2d\)</span>: This is the <strong>Penalty
Term</strong>.</li>
</ul></li>
<li><strong>How it Works:</strong> <span class="math inline">\(AIC =
(\text{Poorness-of-Fit}) + (\text{Complexity Penalty})\)</span>. As you
add predictors, the fit gets better (the deviance term goes down), but
the penalty term (<span class="math inline">\(2d\)</span>) goes up.</li>
<li><strong>Goal:</strong> You select the model with the
<strong>lowest</strong> AIC.</li>
</ul>
<h3 id="bayesian-information-criterion-bic">Bayesian Information
Criterion (BIC)</h3>
<ul>
<li><strong>General Formula:</strong> <span class="math inline">\(BIC =
-2 \log \ell(\hat{\theta}) + \log(n)d\)</span></li>
<li><strong>Concept:</strong> This is mathematically identical to AIC,
but the penalty term is different.
<ul>
<li><strong>AIC Penalty:</strong> <span
class="math inline">\(2d\)</span></li>
<li><strong>BIC Penalty:</strong> <span
class="math inline">\(\log(n)d\)</span></li>
</ul></li>
<li><strong>Comparison:</strong>
<ul>
<li><span class="math inline">\(n\)</span> is the number of observations
in your dataset.</li>
<li>As long as your dataset has 8 or more observations (<span
class="math inline">\(n \ge 8\)</span>), <span
class="math inline">\(\log(n)\)</span> will be greater than 2.</li>
<li>This means <strong>BIC applies a much harsher penalty for
complexity</strong> than AIC.</li>
</ul></li>
<li><strong>Consequence:</strong> BIC will tend to choose
<em>simpler</em> models (fewer predictors) than AIC.</li>
<li><strong>Goal:</strong> You select the model with the
<strong>lowest</strong> BIC.</li>
</ul>
<h2 id="the-deeper-theory-why-aic-works">The Deeper Theory: Why AIC
Works</h2>
<p>Slide 27 (“Understanding AIC”) gives the deep mathematical
justification.</p>
<ul>
<li><strong>Goal:</strong> We have a <em>true</em>, unknown process
<span class="math inline">\(p\)</span> that generates our data. We are
creating a model <span class="math inline">\(\hat{p}_j\)</span>. We want
our model to be as “close” to the truth as possible.</li>
<li><strong>Kullback-Leibler (K-L) Distance:</strong> This is a function
<span class="math inline">\(K(p, \hat{p}_j)\)</span> that measures the
“information lost” when you use your model <span
class="math inline">\(\hat{p}_j\)</span> to approximate the truth <span
class="math inline">\(p\)</span>. You want to <em>minimize</em> this
distance.</li>
<li><strong>The Math:</strong>
<ol type="1">
<li><span class="math inline">\(K(p, \hat{p}_j) = \int p(y) \log \left(
\frac{p(y)}{\hat{p}_j(y)} \right) dy\)</span></li>
<li>This splits into: <span class="math inline">\(K(p, \hat{p}_j) =
\underbrace{\int p(y) \log(p(y)) dy}_{\text{Constant}} -
\underbrace{\int p(y) \log(\hat{p}_j(y)) dy}_{\text{This is what we need
to maximize}}\)</span></li>
</ol></li>
<li><strong>The Problem:</strong> We can’t calculate that second term
because it requires knowing the <em>true</em> function <span
class="math inline">\(p\)</span>.</li>
<li><strong>Akaike’s Insight:</strong> Akaike proved that the
log-likelihood we <em>can</em> calculate, <span
class="math inline">\(\log \ell(\hat{\theta})\)</span>, is a
<em>biased</em> estimator of that target. He also proved that the bias
is approximately <span class="math inline">\(-d\)</span>.</li>
<li><strong>The Solution:</strong> An <em>unbiased</em> estimate of the
target is <span class="math inline">\(\log \ell(\hat{\theta}) -
d\)</span>.</li>
<li><strong>Final Step:</strong> For historical and statistical reasons,
he multiplied this by <span class="math inline">\(-2\)</span> to create
the final AIC formula.</li>
<li><strong>Conclusion:</strong> AIC is not just a random formula. It is
a carefully derived estimate of how much information your model loses
compared to the “truth” (i.e., its expected performance on new
data).</li>
</ul>
<h2 id="aicbic-for-linear-regression">AIC/BIC for Linear Regression</h2>
<p>Slide 26 shows how these general formulas simplify for linear
regression (assuming normal, Gaussian errors).</p>
<ul>
<li><strong>General Formula:</strong> <span class="math inline">\(AIC =
-2 \log \ell(\hat{\theta}) + 2d\)</span></li>
<li><strong>Linear Regression Formula:</strong> <span
class="math inline">\(AIC = \frac{1}{n\hat{\sigma}^2}(RSS +
2d\hat{\sigma}^2)\)</span></li>
</ul>
<p><strong>Key Insight:</strong> For linear regression, the
“poorness-of-fit” term (<span class="math inline">\(-2 \log
\ell(\hat{\theta})\)</span>) is <em>directly proportional to</em> the
<span class="math inline">\(RSS\)</span>.</p>
<p>This makes it much easier to understand. You can just think of the
formulas as: * <strong>AIC <span class="math inline">\(\approx\)</span>
<span class="math inline">\(RSS + 2d\hat{\sigma}^2\)</span></strong> *
<strong>BIC <span class="math inline">\(\approx\)</span> <span
class="math inline">\(RSS + \log(n)d\hat{\sigma}^2\)</span></strong></p>
<p>(Here <span class="math inline">\(\hat{\sigma}^2\)</span> is an
estimate of the error variance, which can often be treated as a
constant).</p>
<p>This clearly shows the trade-off: We want a model with a low
<strong><span class="math inline">\(RSS\)</span></strong> (good fit) and
a low <strong><span class="math inline">\(d\)</span></strong> (low
complexity). These two goals are in direct competition.</p>
<p><strong>Mallow’s <span class="math inline">\(C_p\)</span>:</strong>
The slide notes that <span class="math inline">\(C_p\)</span> is
equivalent to AIC for linear regression. The <span
class="math inline">\(C_p\)</span> formula is <span
class="math inline">\(C_p = \frac{1}{n}(RSS +
2d\hat{\sigma}^2_{full})\)</span>, where <span
class="math inline">\(\hat{\sigma}^2_{full}\)</span> is the error
variance estimated from the <em>full</em> model. Since <span
class="math inline">\(n\)</span> and <span
class="math inline">\(\hat{\sigma}^2_{full}\)</span> are constants,
minimizing <span class="math inline">\(C_p\)</span> is mathematically
identical to minimizing <span class="math inline">\(RSS +
2d\hat{\sigma}^2_{full}\)</span>, which is the same logic as AIC. #
3.</p>
<h1 id="section">4.</h1>
<h1 id="section-1">5.</h1>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Machine-Learning/" rel="tag"># Machine Learning</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/10/06/5054C5/" rel="prev" title="MSDM 5054 - Statistical Machine Learning-L5">
      <i class="fa fa-chevron-left"></i> MSDM 5054 - Statistical Machine Learning-L5
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#linear-model-selection-and-regularization-%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E4%B8%8E%E6%AD%A3%E5%88%99%E5%8C%96"><span class="nav-number">1.</span> <span class="nav-text">1.
Linear Model Selection and Regularization 线性模型选择与正则化</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#summary-of-core-concepts"><span class="nav-number">1.1.</span> <span class="nav-text">Summary of Core Concepts</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#mathematical-understanding-key-questions-%E6%95%B0%E5%AD%A6%E7%90%86%E8%A7%A3%E4%B8%8E%E5%85%B3%E9%94%AE%E9%97%AE%E9%A2%98"><span class="nav-number">1.2.</span> <span class="nav-text">Mathematical
Understanding &amp; Key Questions 数学理解与关键问题</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#how-to-compare-which-model-is-better"><span class="nav-number">1.2.1.</span> <span class="nav-text">How to compare which model
is better?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#why-use-r2-in-step-2"><span class="nav-number">1.2.2.</span> <span class="nav-text">Why use \(R^2\) in Step 2?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#why-cant-we-use-training-error-in-step-3"><span class="nav-number">1.2.3.</span> <span class="nav-text">Why can’t we use
training error in Step 3?</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#code-analysis"><span class="nav-number">1.3.</span> <span class="nav-text">Code Analysis</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#key-functions"><span class="nav-number">1.3.1.</span> <span class="nav-text">Key Functions</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#analysis-of-the-output"><span class="nav-number">1.3.2.</span> <span class="nav-text">Analysis of the Output</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#conceptual-overview-the-why"><span class="nav-number">1.4.</span> <span class="nav-text">Conceptual Overview: The “Why”</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#questions"><span class="nav-number">1.5.</span> <span class="nav-text">Questions 🎯</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#q1-how-to-compare-which-model-is-better"><span class="nav-number">1.5.1.</span> <span class="nav-text">Q1: “How to compare
which model is better?”</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q2-why-using-r2-for-step-2"><span class="nav-number">1.5.2.</span> <span class="nav-text">Q2: “Why using \(R^2\) for step 2?”</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q3-cannot-use-training-error-in-step-3.-why-not-%E6%AD%A5%E9%AA%A4-3-%E4%B8%AD%E4%B8%8D%E8%83%BD%E4%BD%BF%E7%94%A8%E8%AE%AD%E7%BB%83%E8%AF%AF%E5%B7%AE-%E4%B8%BA%E4%BB%80%E4%B9%88"><span class="nav-number">1.5.3.</span> <span class="nav-text">Q3:
“Cannot use training error in Step 3.” Why not? “步骤 3
中不能使用训练误差。” 为什么？</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#mathematical-deep-dive"><span class="nav-number">1.6.</span> <span class="nav-text">Mathematical Deep Dive 🧮</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#detailed-code-analysis"><span class="nav-number">1.7.</span> <span class="nav-text">Detailed Code Analysis 💻</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#key-functions-1"><span class="nav-number">1.7.1.</span> <span class="nav-text">Key Functions</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#summary-of-outputs-slides-...221255.png-...221309.png"><span class="nav-number">1.7.2.</span> <span class="nav-text">Summary
of Outputs (Slides ...221255.png &amp;
...221309.png)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#the-core-problem-training-error-vs.-test-error-%E6%A0%B8%E5%BF%83%E9%97%AE%E9%A2%98%E8%AE%AD%E7%BB%83%E8%AF%AF%E5%B7%AE-vs.-%E6%B5%8B%E8%AF%95%E8%AF%AF%E5%B7%AE"><span class="nav-number">2.</span> <span class="nav-text">2.
The Core Problem: Training Error vs. Test Error 核心问题：训练误差
vs. 测试误差</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#basic-metrics-measures-of-fit"><span class="nav-number">2.1.</span> <span class="nav-text">Basic Metrics (Measures of
Fit)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#residue-error-%E6%AE%8B%E5%B7%AE%E8%AF%AF%E5%B7%AE"><span class="nav-number">2.1.1.</span> <span class="nav-text">Residue (Error) 残差（误差）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#residual-sum-of-squares-rss-%E6%AE%8B%E5%B7%AE%E5%B9%B3%E6%96%B9%E5%92%8C-rss"><span class="nav-number">2.1.2.</span> <span class="nav-text">Residual Sum of
Squares (RSS) 残差平方和 (RSS)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#r-squared-r2"><span class="nav-number">2.1.3.</span> <span class="nav-text">R-squared (\(R^2\))</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#advanced-metrics-for-model-selection-%E9%AB%98%E7%BA%A7%E6%8C%87%E6%A0%87%E7%94%A8%E4%BA%8E%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9"><span class="nav-number">2.2.</span> <span class="nav-text">Advanced
Metrics (For Model Selection) 高级指标（用于模型选择）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#adjusted-r2"><span class="nav-number">2.2.1.</span> <span class="nav-text">Adjusted \(R^2\)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#akaike-information-criterion-aic"><span class="nav-number">2.2.2.</span> <span class="nav-text">Akaike Information Criterion
(AIC)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#bayesian-information-criterion-bic"><span class="nav-number">2.2.3.</span> <span class="nav-text">Bayesian Information
Criterion (BIC)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#the-deeper-theory-why-aic-works"><span class="nav-number">2.3.</span> <span class="nav-text">The Deeper Theory: Why AIC
Works</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#aicbic-for-linear-regression"><span class="nav-number">2.4.</span> <span class="nav-text">AIC&#x2F;BIC for Linear Regression</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#section"><span class="nav-number">3.</span> <span class="nav-text">4.</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#section-1"><span class="nav-number">4.</span> <span class="nav-text">5.</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">15</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
