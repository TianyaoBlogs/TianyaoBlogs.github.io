<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"tianyaoblogs.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="统计机器学习Lecture-3 Lecturer: Prof.XIA DONG 1. General linear regression model.  1.1 general linear regression model  内容: general linear regression model.  the fundamental equation: \[y_i &#x3D; \">
<meta property="og:type" content="article">
<meta property="og:title" content="Statistical Machine Learning-L3">
<meta property="og:url" content="https://tianyaoblogs.github.io/2025/09/16/5054C3/index.html">
<meta property="og:site_name" content="TianyaoBlogs">
<meta property="og:description" content="统计机器学习Lecture-3 Lecturer: Prof.XIA DONG 1. General linear regression model.  1.1 general linear regression model  内容: general linear regression model.  the fundamental equation: \[y_i &#x3D; \">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-09-16T13:00:00.000Z">
<meta property="article:modified_time" content="2025-09-17T05:48:44.112Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="Machine Learning">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://tianyaoblogs.github.io/2025/09/16/5054C3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Statistical Machine Learning-L3 | TianyaoBlogs</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">TianyaoBlogs</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://tianyaoblogs.github.io/2025/09/16/5054C3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="TianyaoBlogs">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Statistical Machine Learning-L3
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-09-16 21:00:00" itemprop="dateCreated datePublished" datetime="2025-09-16T21:00:00+08:00">2025-09-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-09-17 13:48:44" itemprop="dateModified" datetime="2025-09-17T13:48:44+08:00">2025-09-17</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>统计机器学习Lecture-3</p>
<p><a target="_blank" rel="noopener" href="https://www.math.hkust.edu.hk/~madxia/">Lecturer: Prof.XIA
DONG</a></p>
<h1 id="general-linear-regression-model.">1. General linear regression
model.</h1>

<h2 id="general-linear-regression-model">1.1 general linear regression
model</h2>
<ul>
<li><strong>内容</strong>: <strong>general linear regression
model</strong>.</li>
</ul>
<p>the fundamental equation:</p>
<p><span class="math display">\[y_i = \beta_0 + \beta_1x_{i1} + \dots +
\beta_px_{ip} + \epsilon_i\]</span></p>
<p>And it correctly identifies the main goal: to <strong>estimate the
parameters</strong> (the coefficients <span class="math inline">\(\beta_0, \beta_1, \dots, \beta_p\)</span>) from
data so we can make predictions on new data.</p>
<p>核心目标：通过数据<strong>估计参数</strong>（即系数 <span class="math inline">\(\beta_0, \beta_1, \dots,
\beta_p\)</span>），从而对新数据进行预测。</p>
<h2 id="how-we-actually-find-the-best-values-for-the-β-coefficients-parameter-estimation">1.2
How we actually find the best values for the <span class="math inline">\(β\)</span> coefficients (parameter
estimation)?:</h2>
<ul>
<li><strong>内容</strong>: We find the best values for the <span class="math inline">\(\beta\)</span> coefficients by finding the values
that <strong>minimize the overall error</strong> of the model. The most
common and fundamental method for this is called <strong>Ordinary Least
Squares (OLS)</strong>.</li>
</ul>
<hr>
<h3 id="the-main-method-ordinary-least-squares-ols-普通最小二乘法-ols">##
The Main Method: Ordinary Least Squares (OLS) 普通最小二乘法 (OLS)</h3>
<p>The core idea of OLS is to find the line (or hyperplane in multiple
dimensions) that is as close as possible to all the data points
simultaneously. OLS
的核心思想是找到一条尽可能同时接近所有数据点的直线（或多维超平面）。</p>
<h4 id="define-the-error-residuals-误差">1. Define the Error (Residuals)
误差</h4>
<p>First, we need to define what “error” means. For any single data
point, the error is the difference between the actual value (<span class="math inline">\(y_i\)</span>) and the value predicted by our model
(<span class="math inline">\(\hat{y}_i\)</span>). This difference is
called the <strong>residual</strong>.
首先，需要定义“误差”的含义。对于任何单个数据点，误差是实际值 (<span class="math inline">\(y_i\)</span>) 与模型预测值 (<span class="math inline">\(\hat{y}_i\)</span>)
之间的差值。这个差值称为<strong>残差</strong>。</p>
<p><strong>Residual</strong> = Actual Value - Predicted Value
<strong>残差</strong> = 实际值 - 预测值 <span class="math display">\[e_i
= y_i - \hat{y}_i\]</span></p>
<p>You can visualize residuals as the vertical distance from each data
point to the regression line.
可以将残差可视化为每个数据点到回归线的垂直距离。</p>
<h4 id="the-cost-function-sum-of-squared-residuals-成本函数残差平方和">2.
The Cost Function: Sum of Squared Residuals 成本函数：残差平方和</h4>
<p>We want to make all these residuals as small as possible. We can’t
just add them up, because some are positive and some are negative, and
they would cancel each other out.
所有残差尽可能小。不能简单地将它们相加，因为有些是正数，有些是负数，它们会相互抵消。</p>
<p>So, we square each residual (which makes them all positive) and then
sum them up. This gives us the <strong>Sum of Squared Residuals
(SSR)</strong>, which is our “cost function.”
因此，将每个残差求平方（使它们都为正数），然后将它们相加。这就得到了<strong>残差平方和
(SSR)</strong>，也就是“成本函数”。</p>
<p><span class="math display">\[SSR = \sum_{i=1}^{n} e_i^2 =
\sum_{i=1}^{n} (y_i - \hat{y}_i)^2\]</span></p>
<p>The goal of OLS is simple: <strong>find the values of <span class="math inline">\(\beta_0, \beta_1, \dots, \beta_p\)</span> that
make this SSR value as small as possible.</strong></p>
<h4 id="solving-for-the-coefficients-the-normal-equation-求解系数正态方程">3.
Solving for the Coefficients: The Normal Equation
求解系数：正态方程</h4>
<p>For linear regression, calculus provides a direct, exact solution to
this minimization problem. By taking the derivative of the SSR function
with respect to each <span class="math inline">\(\beta\)</span>
coefficient and setting it to zero, we can solve for the optimal values.
对于线性回归，微积分为这个最小化问题提供了直接、精确的解。通过对 SSR
函数的每个 <span class="math inline">\(\beta\)</span>
系数求导并将其设为零，就可以求解出最优值。</p>
<p>This process results in a formula known as the <strong>Normal
Equation</strong>, which can be expressed cleanly using matrix algebra:
这个过程会得到一个称为<strong>正态方程</strong>的公式，它可以用矩阵代数清晰地表示出来：</p>
<p><span class="math display">\[\hat{\boldsymbol{\beta}} =
(\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{y}\]</span></p>
<ul>
<li><span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> is the
vector of our estimated coefficients.估计系数的向量。</li>
<li><span class="math inline">\(\mathbf{X}\)</span> is a matrix where
each row is an observation and each column is a feature (with an added
column of 1s for the intercept <span class="math inline">\(\beta_0\)</span>).其中每一行代表一个观测值，每一列代表一个特征（截距
<span class="math inline">\(\beta_0\)</span> 增加了一列全为 1
的值）。</li>
<li><span class="math inline">\(\mathbf{y}\)</span> is the vector of the
actual response values.实际响应值的向量。</li>
</ul>
<p>Statistical software and programming libraries (like Scikit-learn in
Python) use this equation (or more computationally stable versions of
it) to find the best coefficients for you instantly.</p>
<hr>
<h3 id="an-alternative-method-gradient-descent-梯度下降">## An
Alternative Method: Gradient Descent 梯度下降</h3>
<p>While the Normal Equation gives a direct answer, it can be very slow
if you have a massive number of features (e.g., hundreds of thousands).
An alternative, iterative method used across machine learning is
<strong>Gradient Descent</strong>.</p>
<p><strong>The Intuition:</strong> Imagine the SSR cost function is a
big valley. Your initial (random) <span class="math inline">\(\beta\)</span> coefficients place you somewhere on
the slope of this valley.</p>
<ol type="1">
<li><strong>Check the slope</strong> (the gradient) at your current
position. <strong>检查您当前位置的斜率</strong>（梯度）。</li>
<li><strong>Take a small step</strong> in the steepest <em>downhill</em>
direction. <strong>朝最陡的<em>下坡</em>方向</strong>迈出一小步**。</li>
<li><strong>Repeat.</strong> You keep taking steps downhill until you
reach the bottom of the valley. The bottom of the valley represents the
minimum SSR, and your coordinates at that point are the optimal <span class="math inline">\(\beta\)</span> coefficients.
<strong>重复</strong>。您继续向下走，直到到达山谷底部。谷底代表最小SSR，该点的坐标即为最优<span class="math inline">\(\beta\)</span>系数。</li>
</ol>
<p>The size of each “step” you take is controlled by a parameter called
the <strong>learning rate</strong>. Gradient Descent is the foundational
optimization algorithm for many complex models, including neural
networks.
每次“步进”的大小由一个称为<strong>学习率</strong>的参数控制。梯度下降是许多复杂模型（包括神经网络）的基础优化算法。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Machine-Learning/" rel="tag"># Machine Learning</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/09/15/Pandoc_Deployment/" rel="prev" title="Pandoc Deployment">
      <i class="fa fa-chevron-left"></i> Pandoc Deployment
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#general-linear-regression-model."><span class="nav-number">1.</span> <span class="nav-text">1. General linear regression
model.</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#general-linear-regression-model"><span class="nav-number">1.1.</span> <span class="nav-text">1.1 general linear regression
model</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#how-we-actually-find-the-best-values-for-the-%CE%B2-coefficients-parameter-estimation"><span class="nav-number">1.2.</span> <span class="nav-text">1.2
How we actually find the best values for the \(β\) coefficients (parameter
estimation)?:</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#the-main-method-ordinary-least-squares-ols-%E6%99%AE%E9%80%9A%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95-ols"><span class="nav-number">1.2.1.</span> <span class="nav-text">##
The Main Method: Ordinary Least Squares (OLS) 普通最小二乘法 (OLS)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#define-the-error-residuals-%E8%AF%AF%E5%B7%AE"><span class="nav-number">1.2.1.1.</span> <span class="nav-text">1. Define the Error (Residuals)
误差</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#the-cost-function-sum-of-squared-residuals-%E6%88%90%E6%9C%AC%E5%87%BD%E6%95%B0%E6%AE%8B%E5%B7%AE%E5%B9%B3%E6%96%B9%E5%92%8C"><span class="nav-number">1.2.1.2.</span> <span class="nav-text">2.
The Cost Function: Sum of Squared Residuals 成本函数：残差平方和</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#solving-for-the-coefficients-the-normal-equation-%E6%B1%82%E8%A7%A3%E7%B3%BB%E6%95%B0%E6%AD%A3%E6%80%81%E6%96%B9%E7%A8%8B"><span class="nav-number">1.2.1.3.</span> <span class="nav-text">3.
Solving for the Coefficients: The Normal Equation
求解系数：正态方程</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#an-alternative-method-gradient-descent-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="nav-number">1.2.2.</span> <span class="nav-text">## An
Alternative Method: Gradient Descent 梯度下降</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">5</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
